{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction `get_prices_from_url()` qui extrait des informations à partir des 2 pages ci-dessous.\n",
    "\n",
    "Exemple `URL_PAGE2` doit retourner :\n",
    "\n",
    "<pre>{'Personal': {'price': '$5', 'storage': '1GB', 'databases': 1},\n",
    "  'Small Business': {'price': '$25', 'storage': '10GB', 'databases': 5},\n",
    "  'Enterprise': {'price': '$45', 'storage': '100GB', 'databases': 25}}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Personal': {'price': '$5', 'storage': '1GB', 'databases': 1},\n",
       " 'Small Business': {'price': '$25', 'storage': '10GB', 'databases': 5},\n",
       " 'Enterprise': {'price': '$45', 'storage': '100GB', 'databases': 25}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_PAGE2 = \"https://kim.fspot.org/cours/page2.html\"\n",
    "URL_PAGE3 = \"https://kim.fspot.org/cours/page3.html\"\n",
    "\n",
    "# On importe la librairie python pour les expressions régulières\n",
    "import re\n",
    "\n",
    "def get_prices_from_url(url):\n",
    "    \n",
    "    request = requests.get(url)\n",
    "\n",
    "    # On crée l'objet bs4\n",
    "    soup = BeautifulSoup(request.content)\n",
    "\n",
    "    # on initialise le dictionnaire \"prices\" \n",
    "    prices = {}\n",
    "\n",
    "    # On récupère le numéro de la page html \n",
    "    num_page = url[32]\n",
    "    num_page = int(num_page) # on transforme la variable num_page en entier\n",
    "    #print(type(num_page))\n",
    "\n",
    "    # On sélectionne toutes les divs renfermant toutes les autres divs contenant les informations que l'on souhaite scrapper\n",
    "    soup2 = soup.findAll('div', attrs={'class': f'pure-u-1 pure-u-md-1-{num_page+1}'})\n",
    "\n",
    "    #print(soup2)\n",
    "\n",
    "    # On parcourt toutes les divs contenu dans la variable \"soup2\"\n",
    "    for div in soup2:\n",
    "\n",
    "        # On initialise le dictionnaire qui va contenir les différents prix associé à chaque catégorie de prix (i.e {Personal, Small Business,...})\n",
    "        sub_dic_prices = {}\n",
    "\n",
    "        # on sélectionne la div contenant les infos que l'on souhaite scraper\n",
    "        soup3 = div.find('div', attrs = {'class': f'pricing-table-header'})\n",
    "\n",
    "        # On récupère la catégorie de prix\n",
    "        h2_balise = soup3.find('h2').text\n",
    "        prices[h2_balise] = sub_dic_prices\n",
    "\n",
    "        # On récupère le prix\n",
    "        span_balise = soup3.find('span', attrs = {'class': 'pricing-table-price'})\n",
    "        span_balise_pricing = span_balise.text[-14:-11] # on récupère uniquement la valeur numérique\n",
    "        sub_dic_prices['price'] = span_balise_pricing.strip() # on supprime les blancs dans la chaine de caractères avec la fonction (strip)\n",
    "\n",
    "        # On récupére le 3ème et le 4ème élément de la balise <li> qui sont eux mêmes renfermés dans une balise <ul>\n",
    "        soup4 = div.find('ul', attrs = {'class': 'pricing-table-list'}).findAll('li')\n",
    "        li_3_balise_storage = soup4[3].text.split()[0] # on ne garde que le pattern \"xxxGB\"\n",
    "        sub_dic_prices['storage'] = li_3_balise_storage\n",
    "\n",
    "        li_4_balise_databases = soup4[4].text.split()[0] # on ne garde uniquement le chiffre\n",
    "        sub_dic_prices['databases'] = int(li_4_balise_databases) # on tranforme la valeur en entier\n",
    "    \n",
    "\n",
    "    return prices\n",
    "\n",
    "get_prices_from_url(URL_PAGE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui extrait des informations sur une bière de beowulf.\n",
    "\n",
    "Exemple d'URL: https://www.beerwulf.com/fr-fr/p/bieres/melusine-bio.33 \n",
    "\n",
    "La fonction doit retourner :\n",
    "<pre>\n",
    "{'name': 'Mélusine Bio', 'note': 70, 'price': 38.99, 'volume': 33}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Mélusine Bio', 'note': 70, 'price': 38.99, 'volume': 33}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_beer_infos(url):\n",
    "    \n",
    "    request = requests.get(url)\n",
    "\n",
    "    # On crée l'objet bs4\n",
    "    soup = BeautifulSoup(request.content)\n",
    "\n",
    "    infos = {\n",
    "        'name': None,\n",
    "        'note': None,\n",
    "        'price': None,\n",
    "        'volume': None,\n",
    "    }\n",
    "\n",
    "    # On scrappe le \"name\"\n",
    "    div_name = soup.find('div', attrs = {'class': f'product-detail-info-title'})\n",
    "    h1_balise_name = div_name.find('h1').text\n",
    "    infos[\"name\"] = h1_balise_name\n",
    "\n",
    "    # On scrappe la \"note\"\n",
    "    data_div_note = soup.select('div[data-percent]')\n",
    "    infos[\"note\"] = int(data_div_note[0]['data-percent'])\n",
    "\n",
    "    # On scrappe le \"price\"\n",
    "    span_balise_price = soup.find('span', attrs = {'class': f'price'}).text\n",
    "    span_balise_price_clean = span_balise_price[:-2].replace(\",\", \".\")\n",
    "    span_balice_price_float = float(span_balise_price_clean)\n",
    "    infos[\"price\"] = span_balice_price_float\n",
    "\n",
    "    # On scrappe le \"volume\"\n",
    "    div_balise_volume = soup.find('div', attrs = {'class': f'product-subtext'})\n",
    "    span_balise_volume = div_balise_volume.find('span').text[-6:]\n",
    "    span_balise_volume_cl = span_balise_volume.strip(' cl\\n')\n",
    "    infos[\"volume\"] = int(span_balise_volume_cl)\n",
    "\n",
    "    return infos\n",
    "\n",
    "url = \"https://www.beerwulf.com/fr-fr/p/bieres/melusine-bio.33\"\n",
    "extract_beer_infos(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette URL retourne un JSON avec une liste de bières :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_BEERLIST_FRANCE = \"https://www.beerwulf.com/fr-FR/api/search/searchProducts?country=France&container=Bouteille\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui prend l'argument cet URL retourne les informations sur une liste de bière via l'API de beowulf.\n",
    "\n",
    "Cette fonction doit retourner la liste des informations obtenues par la fonction `extract_beer_infos()` définie ci-dessus.\n",
    "\n",
    "Chercher comment optimiser cette fonction en utilisant multiprocessing.Pool pour paralléliser les accès web.\n",
    "\n",
    "Exemple de retour :\n",
    "\n",
    "<pre>[{'name': 'Gallia East IPA', 'note': 80, 'price': 42.99, 'volume': 33},\n",
    "    {'name': 'La Lager Sans Gluten de Vézelay', 'note': 60, 'price': 38.99, 'volume': 25},\n",
    "    {'name': 'Brasserie De Sutter Brin de Folie', 'note': 70, 'price': 44.99, 'volume': 33},\n",
    "    {'name': 'La Cristal IPA du Mont Blanc', 'note': 70, 'price': 44.99, 'volume': 33},\n",
    "    {'name': 'Mélusine Bio', 'note': 70, 'price': 38.99, 'volume': 33},\n",
    "    {'name': 'La Parisienne Le Titi Parisien', 'note': 70, 'price': 38.99, 'volume': 33},\n",
    "    {'name': 'Gallia Session IPA', 'note': 70, 'price': 42.99, 'volume': 33},\n",
    "    {'name': 'Ninkasi Brut IPA', 'note': 70, 'price': 44.99, 'volume': 33},\n",
    "    {'name': 'Pietra', 'note': 60, 'price': 38.99, 'volume': 33},\n",
    "    {'name': 'Desperados', 'note': 60, 'price': 35.99, 'volume': 33},\n",
    "    {'name': 'Gallia West IPA', 'note': 70, 'price': 42.99, 'volume': 33}]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Gallia East IPA', 'note': 80, 'price': 42.99, 'volume': 33},\n",
       " {'name': 'La Lager Sans Gluten de Vézelay',\n",
       "  'note': 60,\n",
       "  'price': 38.99,\n",
       "  'volume': 25},\n",
       " {'name': 'Brasserie De Sutter Brin de Folie',\n",
       "  'note': 70,\n",
       "  'price': 44.99,\n",
       "  'volume': 33},\n",
       " {'name': 'La Cristal IPA du Mont Blanc',\n",
       "  'note': 70,\n",
       "  'price': 44.99,\n",
       "  'volume': 33},\n",
       " {'name': 'Mélusine Bio', 'note': 70, 'price': 38.99, 'volume': 33},\n",
       " {'name': 'La Parisienne Le Titi Parisien',\n",
       "  'note': 70,\n",
       "  'price': 38.99,\n",
       "  'volume': 33},\n",
       " {'name': 'Gallia Session IPA', 'note': 70, 'price': 42.99, 'volume': 33},\n",
       " {'name': 'Ninkasi Brut IPA', 'note': 70, 'price': 44.99, 'volume': 33},\n",
       " {'name': 'Pietra', 'note': 60, 'price': 38.99, 'volume': 33},\n",
       " {'name': 'Desperados', 'note': 60, 'price': 35.99, 'volume': 33},\n",
       " {'name': 'Gallia West IPA', 'note': 70, 'price': 42.99, 'volume': 33}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def extract_beer_list_infos(url):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    data_beers = response.json()\n",
    "    \n",
    "    # On Collecte les pages de bières à partir de l'API json\n",
    "    beer_pages = ['https://www.beerwulf.com' + item['contentReference'] for item in data_beers['items']]\n",
    "    \n",
    "    # Sequential version (slow):\n",
    "    beers = [extract_beer_infos(url) for url in beer_pages]\n",
    "    \n",
    "\n",
    "    # Parallel version (faster):\n",
    "    #p = Pool()\n",
    "    #beers = p.map(extract_beer_infos,beer_pages)\n",
    "    return beers\n",
    "\n",
    "extract_beer_list_infos(URL_BEERLIST_FRANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Lesson4Tests(unittest.TestCase):\n",
    "    def test_01_get_prices_from_url_page2(self):\n",
    "        prices = get_prices_from_url(URL_PAGE2)\n",
    "        # We should have found 3 products:\n",
    "        self.assertIsInstance(prices, dict)\n",
    "        self.assertEqual(len(prices), 3)\n",
    "        self.assertIn('Personal', prices)\n",
    "        self.assertIn('Small Business', prices)\n",
    "        self.assertIn('Enterprise', prices)\n",
    "        \n",
    "        personal = prices['Personal']\n",
    "        self.assertIn('price', personal)\n",
    "        self.assertIn('storage', personal)\n",
    "        self.assertIn('databases', personal)\n",
    "        self.assertEqual(personal['price'], '$5')\n",
    "        self.assertEqual(personal['storage'], '1GB')\n",
    "        self.assertEqual(personal['databases'], 1)\n",
    "        \n",
    "    def test_02_get_prices_from_url_page3(self):\n",
    "        prices = get_prices_from_url(URL_PAGE3)\n",
    "        self.assertIsInstance(prices, dict)\n",
    "        self.assertEqual(len(prices), 4)\n",
    "        self.assertEqual(\n",
    "            prices['Privilege'],\n",
    "            {'databases': 100, 'price': '$99', 'storage': '1TB'}\n",
    "        )\n",
    "    \n",
    "    def test_03_extract_beer_list_infos(self):\n",
    "        infos = extract_beer_list_infos(URL_BEERLIST_FRANCE)\n",
    "        # We should have 11 French beers:\n",
    "        self.assertIsInstance(infos, list)\n",
    "        self.assertEqual(len(infos), 11)\n",
    "        # All of them are 25cl or 33cl:\n",
    "        for beer in infos:\n",
    "            self.assertIn(beer['volume'], [25, 33])\n",
    "\n",
    "            \n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Lesson4Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_01_get_prices_from_url_page2 (__main__.Lesson4Tests) ... ok\n",
      "test_02_get_prices_from_url_page3 (__main__.Lesson4Tests) ... ok\n",
      "test_03_extract_beer_list_infos (__main__.Lesson4Tests) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 5.323s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
